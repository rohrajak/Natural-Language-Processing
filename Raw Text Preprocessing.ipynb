{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQFAZYx/bJl95vYARDtDGC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# <b>Overview</b>\n","\n","This example demonstrates the fundamental steps of raw text preprocessing in natural language processing (NLP). The code first imports essential Python libraries, then uploads a text dataset for analysis. After loading the data, it tokenizes the sentences—breaking the text into individual words or phrases—preparing it for further linguistic processing.\n","\n"],"metadata":{"id":"QVFY1t_I-bBt"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"smP2GrulNXQ-","executionInfo":{"status":"ok","timestamp":1738918435745,"user_tz":-60,"elapsed":2771,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"f112e49b-bfbd-4758-ebcc-34c51428a4b5","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: autocorrect in /usr/local/lib/python3.11/dist-packages (2.6.1)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["!pip install autocorrect # Install the autocorrect package\n","\n","import nltk # Import the nltk package\n","nltk.download('punkt') # Download the Punkt tokenizer\n","nltk.download('punkt_tab') # Download the Punkt tokenizer\n","from nltk.tokenize import word_tokenize # Import the word_tokenize function# Import the word_tokenize function\n","nltk.download('averaged_perceptron_tagger') # Download the POS tagger\n","nltk.download('stopwords') # Download the stopwords\n","nltk.download('wordnet') # Download the WordNet lemmatizer\n","from nltk import word_tokenize   # Import the word_tokenize function\n","from nltk.stem.wordnet import WordNetLemmatizer   # Import the WordNet lemmatizer\n","from nltk.corpus import stopwords   # Import the stopwords\n","from autocorrect import Speller   # Import the speller checker\n","from nltk.wsd import lesk   # Import the Lesk algorithm\n","from nltk.tokenize import sent_tokenize  # type: ignore # Import the sentence tokenizer\n","import string   # Import the string module"]},{"cell_type":"markdown","source":["## <h2>Libraries Info:</h2>\n","\n","  <ol type=\"1\">\n","    <li>autocorrect: This package provides automatic spelling correction for words. It is useful in text preprocessing to correct common spelling mistakes.</li>\n","    <li>nltk (Natural Language Toolkit): A popular Python library for NLP tasks such as tokenization, lemmatization, part-of-speech tagging, and more.</li>\n","    <li>nltk.download('punkt'): Downloads the Punkt tokenizer, which is a pre-trained sentence and word tokenizer used for splitting text into sentences and words.</li>\n","    <li>word_tokenize (from nltk.tokenize): A function that tokenizes (splits) a given text into words.</li>\n","    <li>nltk.download('averaged_perceptron_tagger'): Downloads the averaged perceptron tagger, which is used for part-of-speech (POS) tagging.</li>\n","    <li>nltk.download('stopwords'): Downloads a predefined list of stopwords (common words like \"the,\" \"is,\" etc.) that are often removed in text processing.</li>\n","    <li>nltk.download('wordnet'): Downloads the WordNet lexical database, which is used for word sense disambiguation and lemmatization.</li>\n","    <li>word_tokenize (from nltk): Re-imports the word_tokenize function for tokenizing text into words. (This is redundant in your code.)</li>\n","    <li>WordNetLemmatizer (from nltk.stem.wordnet): A lemmatizer that reduces words to their base or root form using the WordNet database.</li>\n","    <li>stopwords (from nltk.corpus): Provides a predefined list of common stopwords that can be filtered out from text during preprocessing.</li>\n","    <li>spell (from autocorrect): Provides a spelling correction function that automatically corrects misspelled words. (Note: The correct import should be from autocorrect import Speller and then Speller() instead of spell.)</li>\n","    <li>lesk (from nltk.wsd): Implements the Lesk algorithm, a word sense disambiguation technique that determines the correct meaning of a word based on its surrounding context.</li>\n","    <li>sent_tokenize (from nltk.tokenize): A function that splits text into individual sentences.</li>\n","    <li>string: A built-in Python module that provides tools for working with textual data, including string manipulation and punctuation removal.</li>\n","  </ol>"],"metadata":{"id":"7Z1TuupHDEsJ"}},{"cell_type":"code","source":["sentence = open(\"/content/file.txt\", \"r\").read()   # Read the text file"],"metadata":{"id":"23HdCrmrNwTF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IE2XXx37s6z","executionInfo":{"status":"ok","timestamp":1738918368055,"user_tz":-60,"elapsed":219,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"cb6cf086-ea8b-44cd-ecb5-061eb5de6756"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In this book authored by Sohom Ghosh and Dwight Gunning, we shall learnning how to pracess Natueral Language and extract insights from it. The first four chapter will introduce you to the basics of NLP. Later chapters will describe how to deal with complex NLP prajects. If you want to get early access of it, you should book your order now.\n","\n"]}]},{"cell_type":"code","source":["words = word_tokenize(sentence)   # Tokenize the words"],"metadata":{"id":"hB_B_QcWNzf0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(words[0:10])   # Print the first 20 words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2Uoi_2UN2dI","executionInfo":{"status":"ok","timestamp":1738918379235,"user_tz":-60,"elapsed":201,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"6543061e-e82c-43e3-acdc-4b4c26878a99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['In', 'this', 'book', 'authored', 'by', 'Sohom', 'Ghosh', 'and', 'Dwight', 'Gunning']\n"]}]},{"cell_type":"code","source":["corrected_sentences = \"\"\n","corrected_word_list = []\n","for word in words:\n","  if word not in string.punctuation:\n","    spell = Speller(lang='en')\n","    word_crctd = spell(word)\n","    if word_crctd != word:\n","      print(word+\" has been corrected to: \"+word_crctd)\n","      corrected_sentences = corrected_sentences+\" \"+word_crctd\n","      corrected_word_list.append(word_crctd)\n","    else:\n","      corrected_sentences = corrected_sentences+\" \"+word\n","      corrected_word_list.append(word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKCafSZ8jqOj","executionInfo":{"status":"ok","timestamp":1738918662596,"user_tz":-60,"elapsed":4271,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"adeb83f3-d0c1-4b63-cec1-d10667eb004a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sohom has been corrected to: Show\n","Ghosh has been corrected to: Ghost\n","Dwight has been corrected to: Right\n","Gunning has been corrected to: Running\n","learnning has been corrected to: learning\n","pracess has been corrected to: process\n","Natueral has been corrected to: Natural\n","NLP has been corrected to: LP\n","NLP has been corrected to: LP\n","prajects has been corrected to: projects\n"]}]},{"cell_type":"code","source":["corrected_sentences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"1R5QU3a8j9d0","executionInfo":{"status":"ok","timestamp":1738918662596,"user_tz":-60,"elapsed":5,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"fce33151-f89b-49cf-c691-7f4fcf00ab8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' In this book authored by Show Ghost and Right Running we shall learning how to process Natural Language and extract insights from it The first four chapter will introduce you to the basics of LP Later chapters will describe how to deal with complex LP projects If you want to get early access of it you should book your order now'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["print(corrected_word_list[0:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJzPpvoQoUPt","executionInfo":{"status":"ok","timestamp":1738918708896,"user_tz":-60,"elapsed":198,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"4a656ed0-5e81-489f-9722-3aa4157977c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['In', 'this', 'book', 'authored', 'by', 'Show', 'Ghost', 'and', 'Right', 'Running', 'we', 'shall', 'learning', 'how', 'to', 'process', 'Natural', 'Language', 'and', 'extract']\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('averaged_perceptron_tagger_eng')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6vWlEe3of4c","executionInfo":{"status":"ok","timestamp":1738918930823,"user_tz":-60,"elapsed":222,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"9da33a67-8ba8-4c79-ceb0-744d7638933d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["print(nltk.pos_tag(corrected_word_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w72czozfpBNs","executionInfo":{"status":"ok","timestamp":1738918933464,"user_tz":-60,"elapsed":224,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"74464dd9-502f-40ed-f1e3-e471754ebefa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('In', 'IN'), ('this', 'DT'), ('book', 'NN'), ('authored', 'VBN'), ('by', 'IN'), ('Show', 'NNP'), ('Ghost', 'NNP'), ('and', 'CC'), ('Right', 'NNP'), ('Running', 'NNP'), ('we', 'PRP'), ('shall', 'MD'), ('learning', 'VB'), ('how', 'WRB'), ('to', 'TO'), ('process', 'VB'), ('Natural', 'NNP'), ('Language', 'NNP'), ('and', 'CC'), ('extract', 'JJ'), ('insights', 'NNS'), ('from', 'IN'), ('it', 'PRP'), ('The', 'DT'), ('first', 'JJ'), ('four', 'CD'), ('chapter', 'NN'), ('will', 'MD'), ('introduce', 'VB'), ('you', 'PRP'), ('to', 'TO'), ('the', 'DT'), ('basics', 'NNS'), ('of', 'IN'), ('LP', 'NNP'), ('Later', 'NNP'), ('chapters', 'NNS'), ('will', 'MD'), ('describe', 'VB'), ('how', 'WRB'), ('to', 'TO'), ('deal', 'VB'), ('with', 'IN'), ('complex', 'JJ'), ('LP', 'NNP'), ('projects', 'NNS'), ('If', 'IN'), ('you', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('get', 'VB'), ('early', 'JJ'), ('access', 'NN'), ('of', 'IN'), ('it', 'PRP'), ('you', 'PRP'), ('should', 'MD'), ('book', 'NN'), ('your', 'PRP$'), ('order', 'NN'), ('now', 'RB')]\n"]}]},{"cell_type":"code","source":["stop_words = stopwords.words('english')\n","corrected_word_list_without_stopwords = []\n","for word in corrected_word_list:\n","  if word not in stop_words:\n","    corrected_word_list_without_stopwords.append(word)\n","    print(corrected_word_list_without_stopwords[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDzksKg2pV9U","executionInfo":{"status":"ok","timestamp":1738919378529,"user_tz":-60,"elapsed":228,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"b0d7e783-28f5-422b-d210-9b29334766a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['In']\n","['In', 'book']\n","['In', 'book', 'authored']\n","['In', 'book', 'authored', 'Show']\n","['In', 'book', 'authored', 'Show', 'Ghost']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insights', 'The', 'first', 'four', 'chapter', 'introduce', 'basics']\n"]}]},{"cell_type":"markdown","source":["Stemmer"],"metadata":{"id":"hXaY8eFcrMF8"}},{"cell_type":"code","source":["stemmer = nltk.stem.PorterStemmer()\n","corrected_word_list_without_stopwords_stemmed = []\n","for word in corrected_word_list_without_stopwords:\n","  corrected_word_list_without_stopwords_stemmed.append(stemmer.stem(word))\n","  print(corrected_word_list_without_stopwords_stemmed[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2O_Ql81rIsF","executionInfo":{"status":"ok","timestamp":1738919552408,"user_tz":-60,"elapsed":202,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"67691798-62ea-4ebc-d25e-8e68ce055b34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['in']\n","['in', 'book']\n","['in', 'book', 'author']\n","['in', 'book', 'author', 'show']\n","['in', 'book', 'author', 'show', 'ghost']\n","['in', 'book', 'author', 'show', 'ghost', 'right']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n","['in', 'book', 'author', 'show', 'ghost', 'right', 'run', 'shall', 'learn', 'process', 'natur', 'languag', 'extract', 'insight', 'the', 'first', 'four', 'chapter', 'introduc', 'basic']\n"]}]},{"cell_type":"markdown","source":["Lemmatization"],"metadata":{"id":"Aa_ocQNEr0x8"}},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","corrected_word_list_without_stopwords_lemmatized = []\n","for word in corrected_word_list_without_stopwords:\n","  corrected_word_list_without_stopwords_lemmatized.append(lemmatizer.lemmatize(word))\n","  print(corrected_word_list_without_stopwords_lemmatized[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YpyGO4Hr2qE","executionInfo":{"status":"ok","timestamp":1738919734663,"user_tz":-60,"elapsed":4356,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"9889f681-ca90-43f8-e06e-f3397b37e503"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['In']\n","['In', 'book']\n","['In', 'book', 'authored']\n","['In', 'book', 'authored', 'Show']\n","['In', 'book', 'authored', 'Show', 'Ghost']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n","['In', 'book', 'authored', 'Show', 'Ghost', 'Right', 'Running', 'shall', 'learning', 'process', 'Natural', 'Language', 'extract', 'insight', 'The', 'first', 'four', 'chapter', 'introduce', 'basic']\n"]}]},{"cell_type":"code","source":["print(sent_tokenize(corrected_sentences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2g-aYIkshas","executionInfo":{"status":"ok","timestamp":1738919801714,"user_tz":-60,"elapsed":232,"user":{"displayName":"Rohit Kumar Rajak","userId":"13115330645325188337"}},"outputId":"7b36e77d-1717-4481-c59f-3fe3611a3ce0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' In this book authored by Show Ghost and Right Running we shall learning how to process Natural Language and extract insights from it The first four chapter will introduce you to the basics of LP Later chapters will describe how to deal with complex LP projects If you want to get early access of it you should book your order now']\n"]}]}]}